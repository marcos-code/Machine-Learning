{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cross-validation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP9pjMBq2bAH3cShFQWxT9p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcos-code/Machine-Learning/blob/main/Cross_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sal792j1EM9g"
      },
      "source": [
        "A filosofia que você deve ter na cabeça é que **o primeiro contato de um modelo de machine learning com dados de teste, deve ocorrer apenas na última etapa do processo.**\n",
        "\n",
        "Dentre todos os fatores que nos levam a chegar a essa conclusão, estão os fatos que usar datasets de testes para ajustes, levarão a um provável **overfitting** e carregarão um *bias* (viés).\n",
        "\n",
        "Assim, para que você possa aprender os parâmetros de um modelo e preservar os dados de teste, mostrarei a técnica de **cross-validation**, seguindo o fluxograma da documentação oficial do `sklearn`.\n",
        "\n",
        "<center><img alt=\"Colaboratory logo\" width=\"40%\" src=\"https://raw.githubusercontent.com/carlosfab/dsnp2/master/img/grid_search_workflow.png\"></center>\n",
        "\n",
        "Em tempo, veremos em outra aula como determinar os parâmetros do modelo usando uma técnica conhecida como `grid search`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHdSez8G75Fy"
      },
      "source": [
        "# importar os pacotes necessários\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# garantir replicabilidade\n",
        "np.random.seed(42)\n",
        "\n",
        "# importar o arquivo\n",
        "df = pd.read_csv(\"http://dl.dropboxusercontent.com/s/6d91j46mkcdj4qv/heart-disease-clean.csv?dl=1\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UnCAdlcFeND"
      },
      "source": [
        "#Escolha do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOjVvIcGE1qc",
        "outputId": "1cb28e38-6d00-4b48-aeef-1d7247485c8c"
      },
      "source": [
        "# 1. Escolher e importar um modelo\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "\n",
        "# 2. Instanciar e escolher os hyperparameters\n",
        "model = LogisticRegression()\n",
        "\n",
        "\n",
        "#3. Separar os dados entre feature matrix e target vector\n",
        "X = df.drop('num', axis=1)\n",
        "y= df['num']\n",
        "\n",
        "# 3.1 Dividir o dataset entre o treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
        "\n",
        "# 3.2 Padronizar os dados de treino\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_transformed = scaler.transform(X_train)\n",
        "\n",
        "# 4. Cross-Validation\n",
        "from sklearn.pipeline import make_pipeline\n",
        "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
        "scores = cross_val_score(model, X_train, y_train, cv=5)\n",
        "\n",
        "print(\"scores: \", scores)\n",
        "print(\"Acurácia: %0.2f (+/- %.02f)\" % (scores.mean(), scores.std() * 2))\n",
        "\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scores:  [0.82608696 0.86956522 0.77777778 0.66666667 0.91111111]\n",
            "Acurácia: 0.81 (+/- 0.17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9MM1mPrTWzS"
      },
      "source": [
        "Acima, você pode ver o score médio e o intervalo de confiança de 95%.\n",
        "\n",
        "Por padrão, o score é computado de acordo com o método de score do próprio estimador. No entanto, é possível escolher outra métrica mais alinhada com a realidade do seu dataset.\n",
        "\n",
        "Para conhecer as métricas possíveis, [acesse este link](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UzaMAWIQY1u",
        "outputId": "e6edbdd8-e2f2-4de4-a76b-e3b517dbb9c9"
      },
      "source": [
        "scores = cross_val_score(model, X_train_transformed, y_train, cv=5, scoring=\"f1\")\n",
        "print(\"scores: \", scores)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scores:  [0.8        0.85       0.72222222 0.65116279 0.9       ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7xiStLITzUQ"
      },
      "source": [
        "Aqui eu quero chamar a atenção para uma coisa. Repare que no primeiro modelo, fizemos a padronização do nosso `X_train_transformed = scaler.transform(X_train)` e somente após usamos a técnica de cross-validation.\n",
        "\n",
        "Vou explicar o motivo dessa não ser uma prática adequada. Veja na imagem abaixo que a cada rodada do nosso k-fold (técnica básica de cross-validation), o subconjunto em azul é deixado como \"teste\". \n",
        "\n",
        "<center><img alt=\"Colaboratory logo\" width=\"40%\" src=\"https://raw.githubusercontent.com/carlosfab/dsnp2/master/img/grid_search_cross_validation.png\"></center>\n",
        "\n",
        "Isso não é ideal, pois queremos simular uma condição onde nosso modelo de machine learning nunca tenha visto esse subconjunto.\n",
        "\n",
        "Essa etapa de padronização ou qualquer outra de pré-processamento, pode ser estruturada com um `pipeline`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsRpGmiYTjQd",
        "outputId": "201ae186-23a2-402e-9a31-f4ecfdf37fad"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
        "scores = cross_val_score(model, X_train, y_train, cv=5)\n",
        "\n",
        "print(\"Scores: \", scores)\n",
        "print(\"Acurácia: %0.2f(+/-%0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores:  [0.82608696 0.86956522 0.77777778 0.66666667 0.91111111]\n",
            "Acurácia: 0.81(+/-0.17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyLnfaOvUO1N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}